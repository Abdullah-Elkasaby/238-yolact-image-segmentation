{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as onnxrt\n",
    "import numpy as np\n",
    "from cv2 import imread\n",
    "from torch import from_numpy \n",
    "from utils.augmentations import FastBaseTransform\n",
    "onnx_session= onnxrt.InferenceSession(\"Yolact_Model.onnx\")\n",
    "onnx_inputs= onnx_session.get_inputs()[0].name\n",
    "onnx_labels= onnx_session.get_outputs()[0].name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_frame = from_numpy(imread(\"data/yolact_example_0.png\")).float()\n",
    "onnx_batch = FastBaseTransform()(onnx_frame.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_preds = onnx_session.run(None, {onnx_inputs:onnx_batch.detach().numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= [{'box':onnx_preds[0], 'mask':onnx_preds[1], 'class':onnx_preds[2], 'score':onnx_preds[3], 'proto':onnx_preds[4]}]\n",
    "\n",
    "for key, values in test[0].items():\n",
    "    test[0][key] = from_numpy(np.array(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moded_eval import prep_display\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Config' object has no attribute 'mask_proto_debug'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m onnx_preds \u001b[39m=\u001b[39m onnx_session\u001b[39m.\u001b[39mrun(\u001b[39mNone\u001b[39;00m, {onnx_inputs:batch\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()})\n\u001b[0;32m      5\u001b[0m onnx_preds \u001b[39m=\u001b[39m test\n\u001b[1;32m----> 6\u001b[0m img_numpy \u001b[39m=\u001b[39m prep_display(onnx_preds, frame, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, undo_transform\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      7\u001b[0m img_numpy \u001b[39m=\u001b[39m img_numpy[:, :, (\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)]\n\u001b[0;32m      8\u001b[0m plt\u001b[39m.\u001b[39mimshow(img_numpy)\n",
      "File \u001b[1;32mc:\\Users\\Terep\\Desktop\\Learning\\yolact_cpu\\moded_eval.py:105\u001b[0m, in \u001b[0;36mprep_display\u001b[1;34m(dets_out, img, h, w, undo_transform, class_color, mask_alpha)\u001b[0m\n\u001b[0;32m    102\u001b[0m     h, w, _ \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mshape\n\u001b[0;32m    104\u001b[0m \u001b[39mwith\u001b[39;00m timer\u001b[39m.\u001b[39menv(\u001b[39m'\u001b[39m\u001b[39mPostprocess\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 105\u001b[0m     t \u001b[39m=\u001b[39m postprocess(dets_out, w, h, visualize_lincomb \u001b[39m=\u001b[39;49m args\u001b[39m.\u001b[39;49mdisplay_lincomb,\n\u001b[0;32m    106\u001b[0m                                     crop_masks        \u001b[39m=\u001b[39;49m args\u001b[39m.\u001b[39;49mcrop,\n\u001b[0;32m    107\u001b[0m                                     score_threshold   \u001b[39m=\u001b[39;49m args\u001b[39m.\u001b[39;49mscore_threshold)\n\u001b[0;32m    108\u001b[0m     \u001b[39m# torch.cuda.synchronize()\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[39m# torch.synchronize()\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39mwith\u001b[39;00m timer\u001b[39m.\u001b[39menv(\u001b[39m'\u001b[39m\u001b[39mCopy\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Terep\\Desktop\\Learning\\yolact_cpu\\layers\\output_utils.py:81\u001b[0m, in \u001b[0;36mpostprocess\u001b[1;34m(det_output, w, h, batch_idx, interpolation_mode, visualize_lincomb, crop_masks, score_threshold)\u001b[0m\n\u001b[0;32m     78\u001b[0m proto_data \u001b[39m=\u001b[39m dets[\u001b[39m'\u001b[39m\u001b[39mproto\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     80\u001b[0m \u001b[39m# Test flag, do not upvote\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[39mif\u001b[39;00m cfg\u001b[39m.\u001b[39;49mmask_proto_debug:\n\u001b[0;32m     82\u001b[0m     np\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mscripts/proto.npy\u001b[39m\u001b[39m'\u001b[39m, proto_data\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     84\u001b[0m \u001b[39mif\u001b[39;00m visualize_lincomb:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Config' object has no attribute 'mask_proto_debug'"
     ]
    }
   ],
   "source": [
    "path = \"data/yolact_example_0.png\"\n",
    "frame = from_numpy(imread(path)).float()\n",
    "batch = FastBaseTransform()(frame.unsqueeze(0))\n",
    "onnx_preds = onnx_session.run(None, {onnx_inputs:batch.detach().numpy()})\n",
    "onnx_preds = test\n",
    "img_numpy = prep_display(onnx_preds, frame, None, None, undo_transform=False)\n",
    "img_numpy = img_numpy[:, :, (2, 1, 0)]\n",
    "plt.imshow(img_numpy)\n",
    "plt.title(path)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
